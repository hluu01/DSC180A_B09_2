{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b4c4748-d0b8-4be1-917e-c66beadc5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syllapy\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from readability import Readability\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2c29f4-9c68-42b8-a8be-9b76d44f0bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "import torch\n",
    "import torchvision\n",
    "import tensorflow\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim import corpora, models\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685d01d-abdc-47d6-b97f-18394cfed29f",
   "metadata": {},
   "source": [
    "### Text Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "770b1472-8560-4501-b8ed-66a61b1a1f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_title = \"Mysteries of the Deep, Scientists Uncover Bioluminescent Marvels in Uncharted Oceans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58dd6c86-7b8d-4c05-bba5-ab0e6493c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_article = \"\"\"\n",
    "In a groundbreaking discovery, scientists have identified a new species of marine life in the depths of the ocean. The species, named \"Abyssal Glowfish,\" is known for its bioluminescent properties, creating a mesmerizing display of colors in the dark ocean depths.\n",
    "\n",
    "Researchers conducted an extensive deep-sea expedition, using state-of-the-art submersibles to explore the previously uncharted regions. The Abyssal Glowfish was found thriving at depths of over 5,000 meters, adapting to the pitch-black environment with its unique ability to emit light.\n",
    "\n",
    "This discovery opens up new avenues for understanding the biodiversity of our oceans, with estimates suggesting there could be millions of undiscovered species. The Abyssal Glowfish is just one example of the incredible life that may exist in these unexplored habitats.\n",
    "\n",
    "Furthermore, environmentalists emphasize the importance of conservation efforts to protect these delicate ecosystems. The newfound species highlights the need for responsible stewardship of our oceans to preserve the rich diversity of marine life.\n",
    "\n",
    "The scientific community is abuzz with anticipation for future deep-sea expeditions, hoping to unveil more secrets hidden beneath the ocean's surface. The Abyssal Glowfish serves as a symbol of the wonders yet to be discovered in the mysterious depths of our planet's oceans.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dae84c8-ed6f-4373-adcc-b80a872f638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_article = ' '.join(news_article.split()).replace(\"\\'\", '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7afb562-9136-4386-852c-6dad0e541076",
   "metadata": {},
   "source": [
    "### Flesch-Kincaid Grade Level Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb3c55-dbf7-4db9-812a-b44ef7c67a47",
   "metadata": {},
   "source": [
    "Fleisch readibility score should be between 8-12\n",
    "If score is above 12, take score - 12 = diff and do 100 - (diff * 10)\n",
    "If score is below 8, take 8 - score = diff and do 100 - (diff * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec692f-2163-438d-a15c-3785405129ae",
   "metadata": {},
   "source": [
    "Readibility is very important because it has to do with the credibility of the author. A good author should know that the average american is high school educated, and that they should aim for a reading grade level between 8-12 based on good journalism practice. Ignoring this hinders reliability unless they work for a specialized news source that caters towards a more educated audience. If this is true though, the other scoring metrics should make up for the reduction from this metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6138ac8-a134-430f-8a37-7f5afab64c27",
   "metadata": {},
   "source": [
    "formula = 0.39 * (total words / total sentences) + 11.8 (total syllables / total words) - 15.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b090b00-8273-4448-a632-93d8dab380f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Readability(cleaned_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14777862-7d62-4d4c-bc00-5f510ca10f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fk = r.flesch_kincaid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48209c55-558c-4507-92fa-7423cc0c0327",
   "metadata": {},
   "outputs": [],
   "source": [
    "flesch_score = fk.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ccc0c41-4cac-47dd-bdba-43978e69056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flesch_score > 12:\n",
    "    diff = flesch_score - 12\n",
    "    fk_rating = 100 - (diff * 10)\n",
    "elif flesch_score < 8:\n",
    "    diff = 8 - flesch_score\n",
    "    fk_rating = 100 - (diff * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6a02cd7-700e-4c75-927e-4ef9446c62eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.54633165829148"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fk_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1af7548-07b1-4d67-8ed0-167a44b086af",
   "metadata": {},
   "source": [
    "### Sensationalism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5cbf65b-177a-4780-aefd-b90ef9c60a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "moving_sentiment_value = 0\n",
    "number_of_paragraphs = 0\n",
    "paragraphs = news_article.split('\\n\\n')\n",
    "for i in paragraphs:\n",
    "    cleaned_text = ' '.join(i.split()).replace(\"\\'\", '')\n",
    "    compound_sentiment_score = sia.polarity_scores(cleaned_text)['compound']\n",
    "    moving_sentiment_value += compound_sentiment_score\n",
    "    number_of_paragraphs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20d98c84-7c13-4a9f-97be-4ffe3da1db4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39776"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_sentiment = moving_sentiment_value / number_of_paragraphs\n",
    "overall_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0397abe-746e-471f-af00-a06067984783",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_sent_score = 100\n",
    "if overall_sentiment < -0.2:\n",
    " overall_sent_score = 100 + (overall_sentiment * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd1c41dd-2c46-4628-8b71-6b6db1baa682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_sent_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409f98e-346e-4fe8-98b3-0f0e1b99d3ca",
   "metadata": {},
   "source": [
    "### Clickbait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c86bea3-59ef-41cc-83c8-fff880542bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(confidence):\n",
    "    if confidence < 0.166:\n",
    "        return \"pants-fire\"\n",
    "    elif confidence < 0.33:\n",
    "        return \"false\"\n",
    "    elif confidence < 0.5:\n",
    "        return \"barely-true\"\n",
    "    elif confidence < 0.666:\n",
    "        return \"half-true\"\n",
    "    elif confidence < 0.833:\n",
    "        return \"mostly-true\" \n",
    "    else:\n",
    "        return \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e76a3d7-4da6-4f8b-9163-9ffe27a1d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b7a4f3c-d012-4e47-8281-90c61e149ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_embeddings(text, n, model):\n",
    "    words = text.split()\n",
    "    ngrams = [words[i:i + n] for i in range(len(words) - n + 1)]  \n",
    "    embeddings = [model.wv[gram] for gram in ngrams if all(word in model.wv for word in gram)]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c20769bd-5d5f-4042-ba3d-edcb22abaf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embeddings(tokens, model):\n",
    "    embeddings = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(embeddings, axis=0) if embeddings else np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01f3619d-56d5-436d-8e03-878ab0a4784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(confidence):\n",
    "    if confidence < 0.166:\n",
    "        return \"pants-fire\"\n",
    "    elif confidence < 0.33:\n",
    "        return \"false\"\n",
    "    elif confidence < 0.5:\n",
    "        return \"barely-true\"\n",
    "    elif confidence < 0.666:\n",
    "        return \"half-true\"\n",
    "    elif confidence < 0.833:\n",
    "        return \"mostly-true\" \n",
    "    else:\n",
    "        return \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a632cd7-a484-40ff-9994-3802d435220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clickbait = pd.read_csv(\"Data/Clickbait_Data/clickbait_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6933cdb0-f42f-4caf-a5a0-06bdd2266ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier = Linear SVM, Score (test, accuracy) = 95.67, Training time = 52.63 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Best --> Classifier = Linear SVM, Score (test, accuracy) = 95.67\n"
     ]
    }
   ],
   "source": [
    "#determining clickbait\n",
    "names = [\"Linear SVM\"] \n",
    "\n",
    "classifiers = [SVC(kernel=\"linear\", C=0.025, probability=True)]\n",
    "\n",
    "\n",
    "#Preprocess, train/test split, and \n",
    "clickbait['PreprocessedTitle'] = clickbait['headline'].apply(preprocess_text)\n",
    "X_train_click, X_test_click, y_train_click, y_test_click = train_test_split(clickbait['PreprocessedTitle'], clickbait['clickbait'], test_size=0.2, random_state=42)\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train_click)\n",
    "X_test_counts = count_vectorizer.transform(X_test_click)\n",
    "\n",
    "\n",
    "max_score = 0.0\n",
    "max_class = ''\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    start_time = time.time()\n",
    "    clf.fit(X_train_counts, y_train_click)\n",
    "    score = 100.0 * clf.score(X_test_counts, y_test_click)\n",
    "    print('Classifier = %s, Score (test, accuracy) = %.2f,' %(name, score), 'Training time = %.2f seconds' % (time.time() - start_time))\n",
    "    \n",
    "    if score > max_score:\n",
    "        clf_best = clf\n",
    "        max_score = score\n",
    "        max_class = name\n",
    "\n",
    "print(80*'-' )\n",
    "print('Best --> Classifier = %s, Score (test, accuracy) = %.2f' %(max_class, max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4da0f014-e09c-419a-b4cc-57a6ae250c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_title_processed = preprocess_text(article_title)\n",
    "article_title_vectorized = count_vectorizer.transform([article_title_processed])\n",
    "clickbait_probability = clf_best.predict_proba(article_title_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67fb32c4-0d29-4991-a117-fcb90ca1e2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.6163109881357"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_not_clickbait = clickbait_probability[:, 0]\n",
    "confidence_not_clickbait = confidence_not_clickbait[0] * 100\n",
    "confidence_not_clickbait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b08a16e-66ce-4895-b762-1dda5352be65",
   "metadata": {},
   "source": [
    "### Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9222428-96f6-47c3-97bd-33c976fcd0f8",
   "metadata": {},
   "source": [
    "make dashboard with outcome of each factor and apply appropriate weighting for each factor. After that read up on RAG/LangChain article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e04fc7f-33bd-4271-9307-e9f9cdf642cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/7hrkp8tj05gbr513hzd6bv000000gp/T/ipykernel_3336/488439558.py:2: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n",
      "/var/folders/pb/7hrkp8tj05gbr513hzd6bv000000gp/T/ipykernel_3336/488439558.py:3: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "from dash.dependencies import Input, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9ea07d1-d30a-45dc-98d0-1646ae0aa423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2af39fad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample data (replace with your actual data)\n",
    "not_clickbait_confidence = confidence_not_clickbait\n",
    "sensationalism_score = overall_sent_score\n",
    "readability = fk_rating\n",
    "overall_score = (not_clickbait_confidence + sensationalism_score + readability) / 3\n",
    "\n",
    "# Initialize Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"News Article Truthfulness Dashboard\", style={'text-align': 'center'}),\n",
    "    \n",
    "    # Display selected data\n",
    "    html.Div([\n",
    "        html.H3(\"Examined Article: \" + article_title, style={'text-align': 'center'}),\n",
    "        html.Pre(f\"Clickbait Score: {confidence_not_clickbait}\"),\n",
    "        html.Pre(f\"Sensationalism Score: {overall_sent_score}\"),\n",
    "        html.Pre(f\"Readability Score: {fk_rating}\"),\n",
    "        html.Pre(f\"Overall Truthfulness Score: {overall_score}\")\n",
    "    ], style={'text-align': 'center'})\n",
    "])\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80059f0-d877-46e8-b032-35d88c34829e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
