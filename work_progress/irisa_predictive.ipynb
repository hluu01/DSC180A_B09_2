{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809293ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ba1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ff443",
   "metadata": {},
   "source": [
    "Plans for Next Week: \n",
    "\n",
    "1. Build compound factor\n",
    "2. Build pipeline for veracity verification\n",
    "3. Update doc\n",
    "\n",
    "1. Balance dataset SMOTE\n",
    "2. Ensemble method\n",
    "3. Google search API\n",
    "- Google Search API\n",
    "- Coloab Enterprise\n",
    "4. Maybe try ranking the features\n",
    "5. Give higher weight for higher accuracy model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6820c",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddeeddc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haaretz investigation reveals discrepancies in...</td>\n",
       "      <td>A viral Oct. 28 social media post claimed that...</td>\n",
       "      <td>Haaretz, an Israeli newspaper, said on X that ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wisconsin has historically … and I think large...</td>\n",
       "      <td>In 2016, Wisconsin helped to swing the preside...</td>\n",
       "      <td>Although Wisconsin has voted for more Democrat...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Haaretz investigation reveals discrepancies in...   \n",
       "1  Wisconsin has historically … and I think large...   \n",
       "\n",
       "                                             article  \\\n",
       "0  A viral Oct. 28 social media post claimed that...   \n",
       "1  In 2016, Wisconsin helped to swing the preside...   \n",
       "\n",
       "                                             summary  label  \n",
       "0  Haaretz, an Israeli newspaper, said on X that ...    4.0  \n",
       "1  Although Wisconsin has voted for more Democrat...    3.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_dataset(csv):\n",
    "    df = pd.read_csv(csv)\n",
    "    df = df.drop(columns=[\"percentages\", \"check_nums\"]).drop_duplicates().dropna()\n",
    "    \n",
    "    mapping = {\n",
    "        \"true\": 0,\n",
    "        \"mostly-true\": 1,\n",
    "        \"half-true\": 2,\n",
    "        \"barely-true\": 3,\n",
    "        \"false\": 4,\n",
    "        \"pants-fire\": 5\n",
    "    }\n",
    "    \n",
    "    df[\"label\"] = df[\"label\"].map(mapping)\n",
    "    \n",
    "    df = df[pd.to_numeric(df[\"label\"], errors=\"coerce\").notna()]\n",
    "    df = df[[\"content\",\"article\",\"summaries\",\"label\"]]\n",
    "    df[\"content\"] = df[\"content\"].str.replace(r'[“\\”]', '', regex=True)\n",
    "    df[\"summaries\"] = df[\"summaries\"].str.replace(r'[\\[\\]\\'\"]', '', regex=True)\n",
    "    df.columns = [\"title\", \"article\", \"summary\", \"label\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = read_dataset(\"politifact_data_combined.csv\")\n",
    "df = df = df[df['summary'] != '']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c9b72b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n",
      "314\n",
      "440\n",
      "720\n",
      "3159\n",
      "1062\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,6):\n",
    "    print(len(df[df[\"label\"]==i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "577fa794",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_106/793248694.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15564649",
   "metadata": {},
   "source": [
    "### Feature 1: ClickBait (Cosine Similarity Between Title and Article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d041a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate the TF-IDF for title and article\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_title = tfidf_vectorizer.fit_transform(df[\"title\"])\n",
    "tfidf_article = tfidf_vectorizer.transform(df[\"article\"])\n",
    "\n",
    "\n",
    "# 2. Cosine Similarity\n",
    "\n",
    "cosine = cosine_similarity(tfidf_title, tfidf_article)\n",
    "cosine_sim = cosine.diagonal()\n",
    "\n",
    "df[\"similarity\"] = cosine_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257f032",
   "metadata": {},
   "source": [
    "### Feature 2: Sentiment Analysis  (pos=1, neg=-1, neu=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289c8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Sentiment Analysis Using NLTK\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df[\"sentiment\"] = df[\"article\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6263adf1",
   "metadata": {},
   "source": [
    "### Feature 3: Quality of Writing (Type-Token Ratio (TTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d3944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove stopwords and punctuation & Make lowercase\n",
    "\n",
    "punctuation = set(string.punctuation)\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [w for w in words if w not in stopwords]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    cleaned_text = ''.join([char for char in text if char not in punctuation])\n",
    "    return cleaned_text\n",
    "\n",
    "df[\"article\"] = df[\"article\"].apply(lambda x: x.lower())\n",
    "df[\"article\"] = df[\"article\"].apply(remove_punctuation)\n",
    "df[\"article\"] = df[\"article\"].apply(remove_stopwords)\n",
    "\n",
    "# 2. TTR = unique_words/total_words\n",
    "\n",
    "df['ttr'] = df['article'].apply(lambda x: x.split()).apply(lambda words: len(set(words)) / len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56c613",
   "metadata": {},
   "source": [
    "### Feature 4: Expressiveness (Adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b24dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Open List of Adjectives (Link: https://gist.github.com/hugsy/8910dc78d208e40de42deb29e62df913)\n",
    "    ### Additional Sources: https://github.com/taikuukaits/SimpleWordlists/tree/master\n",
    "\n",
    "with open(\"adjectives.txt\", \"r\") as file:\n",
    "    adjectives = [line.strip() for line in file]\n",
    "    \n",
    "# 2. Count adjectives\n",
    "\n",
    "def count_adjectives(text):\n",
    "    words = text.split()\n",
    "    adjective_count = sum(1 for word in words if word.lower() in adjectives) / len(words)\n",
    "    return adjective_count\n",
    "\n",
    "df[\"adjectives\"] = df[\"article\"].apply(count_adjectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffaac2d",
   "metadata": {},
   "source": [
    "### New DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a272ff1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>similarity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ttr</th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haaretz investigation reveals discrepancies in...</td>\n",
       "      <td>viral oct 28 social media post claimed israel ...</td>\n",
       "      <td>Haaretz, an Israeli newspaper, said on X that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.457559</td>\n",
       "      <td>-0.9994</td>\n",
       "      <td>0.593137</td>\n",
       "      <td>0.031863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wisconsin has historically … and I think large...</td>\n",
       "      <td>2016 wisconsin helped swing presidential vote ...</td>\n",
       "      <td>Although Wisconsin has voted for more Democrat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358756</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.640472</td>\n",
       "      <td>0.098232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Haaretz investigation reveals discrepancies in...   \n",
       "1  Wisconsin has historically … and I think large...   \n",
       "\n",
       "                                             article  \\\n",
       "0  viral oct 28 social media post claimed israel ...   \n",
       "1  2016 wisconsin helped swing presidential vote ...   \n",
       "\n",
       "                                             summary  label  similarity  \\\n",
       "0  Haaretz, an Israeli newspaper, said on X that ...      1    0.457559   \n",
       "1  Although Wisconsin has voted for more Democrat...      1    0.358756   \n",
       "\n",
       "   sentiment       ttr  adjectives  \n",
       "0    -0.9994  0.593137    0.031863  \n",
       "1     0.9919  0.640472    0.098232  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary = df.copy()\n",
    "\n",
    "def binary_map(val):\n",
    "    if val in [0, 1, 2]:\n",
    "        return 0\n",
    "    elif val in [3, 4, 5]:\n",
    "        return 1\n",
    "\n",
    "df_binary['label'] = df_binary['label'].apply(binary_map)\n",
    "\n",
    "df_binary.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b527c9",
   "metadata": {},
   "source": [
    "### Predictions (One vs Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b2d26a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>similarity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ttr</th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haaretz investigation reveals discrepancies in...</td>\n",
       "      <td>viral oct 28 social media post claimed israel ...</td>\n",
       "      <td>Haaretz, an Israeli newspaper, said on X that ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.457559</td>\n",
       "      <td>-0.9994</td>\n",
       "      <td>0.593137</td>\n",
       "      <td>0.031863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wisconsin has historically … and I think large...</td>\n",
       "      <td>2016 wisconsin helped swing presidential vote ...</td>\n",
       "      <td>Although Wisconsin has voted for more Democrat...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.358756</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.640472</td>\n",
       "      <td>0.098232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Haaretz investigation reveals discrepancies in...   \n",
       "1  Wisconsin has historically … and I think large...   \n",
       "\n",
       "                                             article  \\\n",
       "0  viral oct 28 social media post claimed israel ...   \n",
       "1  2016 wisconsin helped swing presidential vote ...   \n",
       "\n",
       "                                             summary  label  similarity  \\\n",
       "0  Haaretz, an Israeli newspaper, said on X that ...    4.0    0.457559   \n",
       "1  Although Wisconsin has voted for more Democrat...    3.0    0.358756   \n",
       "\n",
       "   sentiment       ttr  adjectives  \n",
       "0    -0.9994  0.593137    0.031863  \n",
       "1     0.9919  0.640472    0.098232  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72106e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"title\",\"article\",\"summary\",\"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test_multi = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c8b8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37106382978723407\n",
      "0.534468085106383\n",
      "0.534468085106383\n",
      "0.5395744680851063\n",
      "0.5319148936170213\n",
      "0.5336170212765957\n",
      "0.512340425531915\n",
      "0.534468085106383\n",
      "0.5302127659574468\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(2),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clf = classifier.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test_multi, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d056a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38042553191489364\n",
      "0.534468085106383\n",
      "0.534468085106383\n",
      "0.5293617021276595\n",
      "0.5293617021276595\n",
      "0.534468085106383\n",
      "0.5285106382978724\n",
      "0.534468085106383\n",
      "0.5302127659574468\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(2),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clf = OneVsOneClassifier(classifier).fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test_multi, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28336466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39574468085106385\n",
      "0.5285106382978724\n",
      "0.5191489361702127\n",
      "0.5251063829787234\n",
      "0.531063829787234\n",
      "0.534468085106383\n",
      "0.531063829787234\n",
      "0.5353191489361702\n",
      "0.5293617021276595\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(2),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clf = OneVsRestClassifier(classifier).fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test_multi, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dc25b1",
   "metadata": {},
   "source": [
    "### Predictions (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4020a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_binary.drop(columns=[\"title\",\"article\",\"summary\",\"label\"])\n",
    "y = df_binary[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test_binary = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7246268b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Best --> Classifier = Linear SVM, Score (test, accuracy) = 83.15\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(2),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "max_score = 0.0\n",
    "max_class = ''\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = 100.0 * clf.score(X_test, y_test_binary)\n",
    "\n",
    "    if score > max_score:\n",
    "        clf_best = clf\n",
    "        max_score = score\n",
    "        max_class = name\n",
    "\n",
    "print(80*'-' )\n",
    "print('Best --> Classifier = %s, Score (test, accuracy) = %.2f' %(max_class, max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3e8bb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8212765957446808\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>similarity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ttr</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Milwaukee Brewers are complaining about a ...</td>\n",
       "      <td>state legislature searching way pay stadium up...</td>\n",
       "      <td>Under an early stadium funding proposal, $135 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.605329</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.601653</td>\n",
       "      <td>0.047934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>New York Attorney General Letitia James and Ju...</td>\n",
       "      <td>new york judge ruled last month fraud lawsuit ...</td>\n",
       "      <td>New York officials did not determine the value...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504848</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.562823</td>\n",
       "      <td>0.075731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Under the Obama-Biden administration, we inves...</td>\n",
       "      <td>frozen bottles water slushy popsicles melting ...</td>\n",
       "      <td>Burying power lines can help protect against o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.578070</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.067821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>When I took office, the auto industry was on i...</td>\n",
       "      <td>united auto workers strike leading us automake...</td>\n",
       "      <td>In 2008 and 2009, interventions by the Bush an...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.591055</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.576196</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Just in the last four years, $80 billion in fe...</td>\n",
       "      <td>2024 sen joe manchin dwva reelection manchin s...</td>\n",
       "      <td>Sen. Joe Manchin, D-W.Va., actually understate...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639529</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.599548</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728</th>\n",
       "      <td>State Forces Citizens to Pay for ‘Stargazing P...</td>\n",
       "      <td>update feb 13 2020 free thought project quick ...</td>\n",
       "      <td>Certain state parks on Long Island require vis...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600434</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.604869</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>Very close to 160 million people are now worki...</td>\n",
       "      <td>president donald trump loves brag economytrump...</td>\n",
       "      <td>Trump cited raw employment data in a Milwaukee...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415663</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>0.575150</td>\n",
       "      <td>0.080160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6742</th>\n",
       "      <td>Under my administration, 7 million Americans h...</td>\n",
       "      <td>third state union address president trump clai...</td>\n",
       "      <td>Data shows about 7 million fewer Americans par...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450584</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.609407</td>\n",
       "      <td>0.073620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>Traditionally, the Speaker says: ‘Members of C...</td>\n",
       "      <td>following president donald trump’s 2020 state ...</td>\n",
       "      <td>Between the 2007 and 2018\\xa0addresses, every ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871262</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.464752</td>\n",
       "      <td>0.169713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6763</th>\n",
       "      <td>Cory Booker and all these people couldn't get ...</td>\n",
       "      <td>fox news host sean hannity invited president d...</td>\n",
       "      <td>The Democratic National Committee\\xa0adjusted ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.385642</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.576159</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "11    The Milwaukee Brewers are complaining about a ...   \n",
       "120   New York Attorney General Letitia James and Ju...   \n",
       "123   Under the Obama-Biden administration, we inves...   \n",
       "129   When I took office, the auto industry was on i...   \n",
       "136   Just in the last four years, $80 billion in fe...   \n",
       "...                                                 ...   \n",
       "6728  State Forces Citizens to Pay for ‘Stargazing P...   \n",
       "6739  Very close to 160 million people are now worki...   \n",
       "6742  Under my administration, 7 million Americans h...   \n",
       "6758  Traditionally, the Speaker says: ‘Members of C...   \n",
       "6763  Cory Booker and all these people couldn't get ...   \n",
       "\n",
       "                                                article  \\\n",
       "11    state legislature searching way pay stadium up...   \n",
       "120   new york judge ruled last month fraud lawsuit ...   \n",
       "123   frozen bottles water slushy popsicles melting ...   \n",
       "129   united auto workers strike leading us automake...   \n",
       "136   2024 sen joe manchin dwva reelection manchin s...   \n",
       "...                                                 ...   \n",
       "6728  update feb 13 2020 free thought project quick ...   \n",
       "6739  president donald trump loves brag economytrump...   \n",
       "6742  third state union address president trump clai...   \n",
       "6758  following president donald trump’s 2020 state ...   \n",
       "6763  fox news host sean hannity invited president d...   \n",
       "\n",
       "                                                summary  label  similarity  \\\n",
       "11    Under an early stadium funding proposal, $135 ...      1    0.605329   \n",
       "120   New York officials did not determine the value...      1    0.504848   \n",
       "123   Burying power lines can help protect against o...      1    0.578070   \n",
       "129   In 2008 and 2009, interventions by the Bush an...      1    0.591055   \n",
       "136   Sen. Joe Manchin, D-W.Va., actually understate...      0    0.639529   \n",
       "...                                                 ...    ...         ...   \n",
       "6728  Certain state parks on Long Island require vis...      1    0.600434   \n",
       "6739  Trump cited raw employment data in a Milwaukee...      0    0.415663   \n",
       "6742  Data shows about 7 million fewer Americans par...      0    0.450584   \n",
       "6758  Between the 2007 and 2018\\xa0addresses, every ...      0    0.871262   \n",
       "6763  The Democratic National Committee\\xa0adjusted ...      0    0.385642   \n",
       "\n",
       "      sentiment       ttr  adjectives  predictions  \n",
       "11       0.9092  0.601653    0.047934            0  \n",
       "120      0.9966  0.562823    0.075731            0  \n",
       "123      0.9899  0.575758    0.067821            0  \n",
       "129      0.9849  0.576196    0.068966            0  \n",
       "136      0.9742  0.599548    0.067873            0  \n",
       "...         ...       ...         ...          ...  \n",
       "6728     0.9949  0.604869    0.078652            0  \n",
       "6739     0.9964  0.575150    0.080160            0  \n",
       "6742     0.9679  0.609407    0.073620            0  \n",
       "6758     0.9996  0.464752    0.169713            0  \n",
       "6763     0.9973  0.576159    0.072848            0  \n",
       "\n",
       "[221 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(df_binary.drop(columns=[\"title\",\"article\",\"summary\",\"label\"]))\n",
    "df_binary[\"predictions\"] = predictions\n",
    "\n",
    "print(accuracy_score(y_test_binary, clf.predict(X_test)))\n",
    "\n",
    "df_binary[df_binary[\"predictions\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26bd8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_binary.drop(columns=[\"title\",\"article\",\"summary\",\"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7abd61ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534468085106383\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel=\"linear\", C=0.025)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(accuracy_score(y_test_multi, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37110fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
